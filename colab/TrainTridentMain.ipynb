{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrainTridentMain.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMwy8EJP0FeZjhJgqMk7Yvj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ag2kCPtZFBAH","executionInfo":{"status":"ok","timestamp":1624054305187,"user_tz":420,"elapsed":148,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"}}},"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","import numpy as np\n","# torch imports\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVbjazrSFgB2","executionInfo":{"status":"ok","timestamp":1624052397587,"user_tz":420,"elapsed":19477,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"}},"outputId":"cce1ed1c-7ec8-4a03-9acd-c02332fa3f31"},"source":["# Run this once\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","# You will have to modify this based on your Google Drive directory structure\n","%cd /content/gdrive/MyDrive/Colab Notebooks/RideStream/\n","!pwd"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/Colab Notebooks/RideStream\n","/content/gdrive/MyDrive/Colab Notebooks/RideStream\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UVr-wVukIkfA","executionInfo":{"status":"ok","timestamp":1624052399780,"user_tz":420,"elapsed":230,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"}}},"source":["class UTKDataset(Dataset):\n","    '''\n","        Inputs:\n","            dataFrame : Pandas dataFrame\n","            transform : The transform to apply to the dataset\n","    '''\n","    def __init__(self, dataFrame, transform=None):\n","        # read in the transforms\n","        self.transform = transform\n","        \n","        # Use the dataFrame to get the pixel values\n","        data_holder = dataFrame.pixels.apply(lambda x: np.array(x.split(\" \"),dtype=float))\n","        arr = np.stack(data_holder)\n","        arr = arr / 255.0\n","        arr = arr.astype('float32')\n","        arr = arr.reshape(arr.shape[0], 48, 48, 1)\n","        # reshape into 48x48x1\n","        self.data = arr\n","        \n","        # get the age, gender, and ethnicity label arrays\n","        self.age_label = np.array(dataFrame.bins[:])        # Note : Changed dataFrame.age to dataFrame.bins with most recent change\n","        self.gender_label = np.array(dataFrame.gender[:])\n","        self.eth_label = np.array(dataFrame.ethnicity[:])\n","    \n","    # override the length function\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    # override the getitem function\n","    def __getitem__(self, index):\n","        # load the data at index and apply transform\n","        data = self.data[index]\n","        data = self.transform(data)\n","        \n","        # load the labels into a list and convert to tensors\n","        labels = torch.tensor((self.age_label[index], self.gender_label[index], self.eth_label[index]))\n","        \n","        # return data labels\n","        return data, labels"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxkn0VdIIlQO","executionInfo":{"status":"ok","timestamp":1624052401669,"user_tz":420,"elapsed":239,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"}}},"source":["# High level feature extractor network (Adopted VGG type structure)\n","class highLevelNN(nn.Module):\n","    def __init__(self):\n","        super(highLevelNN, self).__init__()\n","        self.CNN = nn.Sequential(\n","            # first batch (32)\n","            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","\n","            # second batch (64)\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","\n","            # Third Batch (128)\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","\n","    def forward(self, x):\n","        out = self.CNN(x)\n","\n","        return out\n","\n","# Low level feature extraction module\n","class lowLevelNN(nn.Module):\n","    def __init__(self, num_out):\n","        super(lowLevelNN, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n","        self.fc1 = nn.Linear(in_features=2048, out_features=256)\n","        self.fc2 = nn.Linear(in_features=256, out_features=128)\n","        self.fc3 = nn.Linear(in_features=128, out_features=64)\n","        self.fc4 = nn.Linear(in_features=64, out_features=num_out)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=2, padding=1))\n","        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=3, stride=2, padding=1))\n","        x = torch.flatten(x, start_dim=1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = self.fc4(x)\n","\n","        return x\n","\n","\n","class TridentNN(nn.Module):\n","    def __init__(self, num_age, num_gen, num_eth):\n","        super(TridentNN, self).__init__()\n","        # Construct the high level neural network\n","        self.CNN = highLevelNN()\n","        # Construct the low level neural networks\n","        self.ageNN = lowLevelNN(num_out=num_age)\n","        self.genNN = lowLevelNN(num_out=num_gen)\n","        self.ethNN = lowLevelNN(num_out=num_eth)\n","\n","    def forward(self, x):\n","        x = self.CNN(x)\n","        age = self.ageNN(x)\n","        gen = self.genNN(x)\n","        eth = self.ethNN(x)\n","\n","        return age, gen, eth"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"S78Li3j0JeB8","executionInfo":{"status":"ok","timestamp":1624054659108,"user_tz":420,"elapsed":190,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"}}},"source":["'''\n","    Function to test the trained model\n","\n","    Inputs:\n","      - testloader : PyTorch DataLoader containing the test dataset\n","      - modle : Trained NeuralNetwork\n","    \n","    Outputs:\n","      - Prints out test accuracy for gender and ethnicity and loss for age\n","'''\n","def test(testloader, model):\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu' \n","  size = len(testloader.dataset)\n","  # put the moel in evaluation mode so we aren't storing anything in the graph\n","  model.eval()\n","\n","  age_acc, gen_acc, eth_acc = 0, 0, 0\n","\n","  with torch.no_grad():\n","      for X, y in testloader:\n","          X = X.to(device)\n","          age, gen, eth = y[:,0].to(device), y[:,1].to(device), y[:,2].to(device)\n","          pred = model(X)\n","\n","          age_acc += (pred[0].argmax(1) == age).type(torch.float).sum().item()\n","          gen_acc += (pred[1].argmax(1) == gen).type(torch.float).sum().item()\n","          eth_acc += (pred[2].argmax(1) == eth).type(torch.float).sum().item()\n","\n","  age_acc /= size\n","  gen_acc /= size\n","  eth_acc /= size\n","\n","  print(f\"Age Accuracy : {age_acc*100}%,     Gender Accuracy : {gen_acc*100},    Ethnicity Accuracy : {eth_acc*100}\\n\")"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9QWQfreI_qW","executionInfo":{"status":"ok","timestamp":1624053963605,"user_tz":420,"elapsed":11082,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"}},"outputId":"017215ff-675b-437b-c638-c4dcf72641be"},"source":["# Read in the dataframe\n","dataFrame = pd.read_csv('age_gender.gz', compression='gzip')\n","\n","# Construct age bins\n","age_bins = [0,10,15,20,25,30,40,50,60,120]\n","age_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n","dataFrame['bins'] = pd.cut(dataFrame.age, bins=age_bins, labels=age_labels)\n","\n","# Split into training and testing\n","train_dataFrame, test_dataFrame = train_test_split(dataFrame, test_size=0.2)\n","\n","# get the number of unique classes for each group\n","class_nums = {'age_num':len(dataFrame['bins'].unique()), 'eth_num':len(dataFrame['ethnicity'].unique()),\n","              'gen_num':len(dataFrame['gender'].unique())}\n","'''\n","class_nums = {'age_num':1, 'eth_num':len(dataFrame['ethnicity'].unique()),\n","              'gen_num':len(dataFrame['gender'].unique())}\n","'''\n","\n","# Define train and test transforms\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.49,), (0.23,))\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.49,), (0.23,))\n","])\n","\n","# Construct the custom pytorch datasets\n","train_set = UTKDataset(train_dataFrame, transform=train_transform)\n","test_set = UTKDataset(test_dataFrame, transform=test_transform)\n","\n","# Load the datasets into dataloaders\n","trainloader = DataLoader(train_set, batch_size=64, shuffle=True)\n","testloader = DataLoader(test_set, batch_size=128, shuffle=False)\n","\n","# Sanity Check\n","for X, y in trainloader:\n","    print(f'Shape of training X: {X.shape}')\n","    print(f'Shape of y: {y.shape}')\n","    break"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Shape of training X: torch.Size([64, 1, 48, 48])\n","Shape of y: torch.Size([64, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KHME6XaiB4RA","executionInfo":{"status":"ok","timestamp":1624053999222,"user_tz":420,"elapsed":154,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"}},"outputId":"a410ed61-bd19-484b-d55c-a5c252d4b162"},"source":["# Configure the device \n","device = 'cuda' if torch.cuda.is_available() else 'cpu' \n","print(device)\n","\n","# Define the list of hyperparameters\n","hyperparameters = {'learning_rate':0.001, 'epochs':30}\n","\n","# Initialize the TridentNN model and put on device\n","model = TridentNN(class_nums['age_num'], class_nums['gen_num'], class_nums['eth_num'])\n","model.to(device)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["TridentNN(\n","  (CNN): highLevelNN(\n","    (CNN): Sequential(\n","      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU()\n","      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (4): ReLU()\n","      (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (6): ReLU()\n","      (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (9): ReLU()\n","      (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (11): ReLU()\n","      (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (13): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (14): ReLU()\n","    )\n","  )\n","  (ageNN): lowLevelNN(\n","    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fc1): Linear(in_features=2048, out_features=256, bias=True)\n","    (fc2): Linear(in_features=256, out_features=128, bias=True)\n","    (fc3): Linear(in_features=128, out_features=64, bias=True)\n","    (fc4): Linear(in_features=64, out_features=9, bias=True)\n","  )\n","  (genNN): lowLevelNN(\n","    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fc1): Linear(in_features=2048, out_features=256, bias=True)\n","    (fc2): Linear(in_features=256, out_features=128, bias=True)\n","    (fc3): Linear(in_features=128, out_features=64, bias=True)\n","    (fc4): Linear(in_features=64, out_features=2, bias=True)\n","  )\n","  (ethNN): lowLevelNN(\n","    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fc1): Linear(in_features=2048, out_features=256, bias=True)\n","    (fc2): Linear(in_features=256, out_features=128, bias=True)\n","    (fc3): Linear(in_features=128, out_features=64, bias=True)\n","    (fc4): Linear(in_features=64, out_features=5, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"M1e1Yf_bE2bt","executionInfo":{"status":"ok","timestamp":1624054001685,"user_tz":420,"elapsed":146,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"}}},"source":["'''\n","  Functions to load and save a PyTorch model\n","'''\n","def save_checkpoint(state, epoch):\n","  print(\"Saving Checkpoint\")\n","  filename = \"tridentNN_epoch\"+str(epoch)+\".pth.tar\"\n","  torch.save(state,filename)\n","\n","def load_checkpoint(checkpoint):\n","  print(\"Loading Checkpoint\")\n","  model.load_state_dict(checkpoint['state_dict'])\n","  opt.load_state_dict(checkpoint['optimizer'])\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"FGdpJIvvJZWk","executionInfo":{"status":"error","timestamp":1624054575708,"user_tz":420,"elapsed":253766,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"}},"outputId":"87e7214d-35c1-4bec-a921-209981ab7862"},"source":["'''\n","train the model\n","''' \n","# Load hyperparameters\n","learning_rate = hyperparameters['learning_rate']\n","num_epoch = hyperparameters['epochs']\n","\n","# Define loss functions\n","age_loss = nn.CrossEntropyLoss()\n","gen_loss = nn.CrossEntropyLoss() # TODO : Explore using Binary Cross Entropy Loss?\n","eth_loss = nn.CrossEntropyLoss()\n","\n","# Define optimizer\n","opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Initialize the summaryWriter\n","# writer = SummaryWriter(f'LR: {learning_rate}')\n","\n","# Train the model\n","for epoch in range(num_epoch):\n","  # Construct tqdm loop to keep track of training\n","  loop = tqdm(enumerate(trainloader), total=len(trainloader), position=0, leave=True)\n","  age_correct, gen_correct, eth_correct, total = 0,0,0,0\n","\n","  # save the model every 10 epochs\n","  if epoch % 10 == 0:\n","    checkpoint = {'state_dict' : model.state_dict(), 'optimizer' : opt.state_dict(), \n","                  'age_loss' : age_loss, 'gen_loss' : gen_loss, 'eth_loss' : eth_loss}\n","    save_checkpoint(checkpoint, epoch)\n","\n","  # Loop through dataLoader\n","  for _, (X,y) in loop:\n","    # Unpack y to get true age, eth, and gen values\n","    # Have to do some special changes to age label to make it compatible with NN output and Loss function\n","    #age, gen, eth = y[:,0].resize_(len(y[:,0]),1).float().to(device), y[:,1].to(device), y[:,2].to(device)\n","    age, gen, eth = y[:,0].to(device), y[:,1].to(device), y[:,2].to(device)\n","    X = X.to(device)\n","    pred = model(X)          # Forward pass\n","    loss = age_loss(pred[0],age) + gen_loss(pred[1],gen) + eth_loss(pred[2],eth)   # Loss calculation\n","\n","    # Backpropagation\n","    opt.zero_grad()          # Zero the gradient\n","    loss.backward()          # Calculate updates\n","\n","    # Gradient Descent\n","    opt.step()               # Apply updates\n","\n","    # Update num correct and total\n","    age_correct += (pred[0].argmax(1) == age).type(torch.float).sum().item()\n","    gen_correct += (pred[1].argmax(1) == gen).type(torch.float).sum().item()\n","    eth_correct += (pred[2].argmax(1) == eth).type(torch.float).sum().item()\n","\n","    total += len(y)\n","\n","    # Update progress bar\n","    loop.set_description(f\"Epoch [{epoch+1}/{num_epoch}]\")\n","    loop.set_postfix(loss = loss.item())\n","\n","  # Update epoch accuracy\n","  gen_acc, eth_acc, age_acc = gen_correct/total, eth_correct/total, age_correct/total\n","\n","  # print out accuracy and loss for epoch\n","  print(f'Epoch : {epoch+1}/{num_epoch},    Age Accuracy : {age_acc*100},    Gender Accuracy : {gen_acc*100},    Ethnicity Accuracy : {eth_acc*100}\\n')"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Epoch [1/30]:   0%|          | 1/297 [00:00<00:44,  6.65it/s, loss=1.48]"],"name":"stderr"},{"output_type":"stream","text":["Saving Checkpoint\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [1/30]: 100%|██████████| 297/297 [00:10<00:00, 27.40it/s, loss=1.84]\n","Epoch [2/30]:   1%|          | 3/297 [00:00<00:10, 28.54it/s, loss=1.12]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 1/30,    Age Accuracy : 56.950010546298245,    Gender Accuracy : 94.49483231385784,    Ethnicity Accuracy : 85.62539548618435\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [2/30]: 100%|██████████| 297/297 [00:10<00:00, 28.32it/s, loss=1.21]\n","Epoch [3/30]:   1%|          | 3/297 [00:00<00:10, 28.19it/s, loss=1.26]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 2/30,    Age Accuracy : 59.51276102088167,    Gender Accuracy : 95.13288335794137,    Ethnicity Accuracy : 87.6028264079308\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [3/30]: 100%|██████████| 297/297 [00:10<00:00, 28.08it/s, loss=1.97]\n","Epoch [4/30]:   1%|          | 3/297 [00:00<00:10, 28.46it/s, loss=1.32]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 3/30,    Age Accuracy : 61.78021514448429,    Gender Accuracy : 95.58110103353724,    Ethnicity Accuracy : 88.60999789074036\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [4/30]: 100%|██████████| 297/297 [00:10<00:00, 28.07it/s, loss=1.35]\n","Epoch [5/30]:   1%|          | 3/297 [00:00<00:10, 28.70it/s, loss=1.3] "],"name":"stderr"},{"output_type":"stream","text":["Epoch : 4/30,    Age Accuracy : 63.70491457498419,    Gender Accuracy : 96.00822611263446,    Ethnicity Accuracy : 89.43788230331154\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [5/30]: 100%|██████████| 297/297 [00:10<00:00, 28.08it/s, loss=1.36]\n","Epoch [6/30]:   1%|          | 3/297 [00:00<00:10, 29.11it/s, loss=1.11] "],"name":"stderr"},{"output_type":"stream","text":["Epoch : 5/30,    Age Accuracy : 65.38704914574984,    Gender Accuracy : 96.37734655136047,    Ethnicity Accuracy : 91.05146593545666\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [6/30]: 100%|██████████| 297/297 [00:10<00:00, 27.99it/s, loss=1.26]\n","Epoch [7/30]:   1%|          | 3/297 [00:00<00:09, 29.75it/s, loss=1.01] "],"name":"stderr"},{"output_type":"stream","text":["Epoch : 6/30,    Age Accuracy : 67.71250790972368,    Gender Accuracy : 96.57245306897279,    Ethnicity Accuracy : 91.67369753216622\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [7/30]: 100%|██████████| 297/297 [00:10<00:00, 28.04it/s, loss=1.03]\n","Epoch [8/30]:   1%|          | 3/297 [00:00<00:10, 28.73it/s, loss=0.844]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 7/30,    Age Accuracy : 69.51592491035646,    Gender Accuracy : 97.25268930605357,    Ethnicity Accuracy : 92.7968782957182\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [8/30]: 100%|██████████| 297/297 [00:10<00:00, 28.12it/s, loss=0.853]\n","Epoch [9/30]:   1%|          | 3/297 [00:00<00:10, 28.13it/s, loss=0.931]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 8/30,    Age Accuracy : 72.12086057793714,    Gender Accuracy : 97.51107361316178,    Ethnicity Accuracy : 93.45602193630036\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [9/30]: 100%|██████████| 297/297 [00:10<00:00, 28.16it/s, loss=1.03]\n","Epoch [10/30]:   1%|          | 3/297 [00:00<00:10, 28.34it/s, loss=0.734]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 9/30,    Age Accuracy : 74.36722210504114,    Gender Accuracy : 97.57962455178233,    Ethnicity Accuracy : 94.27336005062223\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [10/30]: 100%|██████████| 297/297 [00:10<00:00, 28.05it/s, loss=0.517]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 10/30,    Age Accuracy : 77.00379666736976,    Gender Accuracy : 97.82746256064121,    Ethnicity Accuracy : 94.7584897700907\n","\n","Saving Checkpoint\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [11/30]: 100%|██████████| 297/297 [00:10<00:00, 27.11it/s, loss=0.688]\n","Epoch [12/30]:   1%|          | 3/297 [00:00<00:10, 28.18it/s, loss=0.404]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 11/30,    Age Accuracy : 78.45918582577515,    Gender Accuracy : 98.13330520987134,    Ethnicity Accuracy : 95.46509175279478\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [12/30]: 100%|██████████| 297/297 [00:10<00:00, 27.88it/s, loss=0.456]\n","Epoch [13/30]:   1%|          | 3/297 [00:00<00:10, 29.20it/s, loss=0.513]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 12/30,    Age Accuracy : 79.17633410672855,    Gender Accuracy : 98.38641636785488,    Ethnicity Accuracy : 95.96076777051255\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [13/30]: 100%|██████████| 297/297 [00:10<00:00, 28.11it/s, loss=0.508]\n","Epoch [14/30]:   1%|          | 3/297 [00:00<00:10, 29.21it/s, loss=0.701]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 13/30,    Age Accuracy : 80.94283906348872,    Gender Accuracy : 98.41278211347817,    Ethnicity Accuracy : 96.13478169162623\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [14/30]: 100%|██████████| 297/297 [00:10<00:00, 28.07it/s, loss=0.733]\n","Epoch [15/30]:   1%|          | 3/297 [00:00<00:10, 27.56it/s, loss=0.584]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 14/30,    Age Accuracy : 82.15039021303522,    Gender Accuracy : 98.46551360472475,    Ethnicity Accuracy : 96.53554102510019\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [15/30]: 100%|██████████| 297/297 [00:10<00:00, 28.03it/s, loss=0.785]\n","Epoch [16/30]:   1%|          | 3/297 [00:00<00:10, 28.28it/s, loss=0.589]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 15/30,    Age Accuracy : 84.37565914364058,    Gender Accuracy : 98.66062012233706,    Ethnicity Accuracy : 96.66209660409196\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [16/30]: 100%|██████████| 297/297 [00:10<00:00, 28.03it/s, loss=0.642]\n","Epoch [17/30]:   1%|          | 3/297 [00:00<00:10, 29.08it/s, loss=0.477]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 16/30,    Age Accuracy : 84.77114532798987,    Gender Accuracy : 98.69753216620965,    Ethnicity Accuracy : 96.67264290234128\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [17/30]: 100%|██████████| 297/297 [00:10<00:00, 27.98it/s, loss=0.235]\n","Epoch [18/30]:   1%|          | 3/297 [00:00<00:10, 28.22it/s, loss=0.312]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 17/30,    Age Accuracy : 86.44273360050623,    Gender Accuracy : 98.82408774520144,    Ethnicity Accuracy : 97.30542079730014\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [18/30]: 100%|██████████| 297/297 [00:10<00:00, 28.01it/s, loss=0.47]\n","Epoch [19/30]:   1%|          | 3/297 [00:00<00:10, 28.39it/s, loss=0.368]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 18/30,    Age Accuracy : 86.77494199535964,    Gender Accuracy : 98.80826829782747,    Ethnicity Accuracy : 97.5321662096604\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [19/30]: 100%|██████████| 297/297 [00:10<00:00, 27.81it/s, loss=1.13]\n","Epoch [20/30]:   1%|          | 3/297 [00:00<00:10, 28.26it/s, loss=0.439]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 19/30,    Age Accuracy : 88.21978485551571,    Gender Accuracy : 98.97700906981649,    Ethnicity Accuracy : 97.54271250790973\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [20/30]: 100%|██████████| 297/297 [00:10<00:00, 27.98it/s, loss=0.329]\n","  0%|          | 0/297 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 20/30,    Age Accuracy : 88.9000210925965,    Gender Accuracy : 98.89791183294663,    Ethnicity Accuracy : 97.7061801307741\n","\n","Saving Checkpoint\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [21/30]: 100%|██████████| 297/297 [00:11<00:00, 26.91it/s, loss=0.517]\n","Epoch [22/30]:   1%|          | 3/297 [00:00<00:10, 28.08it/s, loss=0.282]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 21/30,    Age Accuracy : 89.37987766294032,    Gender Accuracy : 99.05610630668636,    Ethnicity Accuracy : 97.71145327989875\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [22/30]: 100%|██████████| 297/297 [00:10<00:00, 27.95it/s, loss=0.702]\n","Epoch [23/30]:   1%|          | 3/297 [00:00<00:10, 28.26it/s, loss=0.487]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 22/30,    Age Accuracy : 89.98628981227588,    Gender Accuracy : 99.04028685931237,    Ethnicity Accuracy : 97.73781902552204\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [23/30]: 100%|██████████| 297/297 [00:10<00:00, 27.92it/s, loss=0.0925]\n","Epoch [24/30]:   1%|          | 3/297 [00:00<00:10, 26.90it/s, loss=0.297]"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 23/30,    Age Accuracy : 90.42396118962243,    Gender Accuracy : 99.10356464880827,    Ethnicity Accuracy : 97.62180974477958\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [24/30]:  81%|████████  | 240/297 [00:08<00:02, 27.54it/s, loss=0.28] "],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-fe47f36e6ad6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# Loop through dataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Unpack y to get true age, eth, and gen values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Have to do some special changes to age label to make it compatible with NN output and Loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-fada03233caa>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# load the data at index and apply transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# load the labels into a list and convert to tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'std evaluated to zero after conversion to {}, leading to division by zero.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"F9sxKcPyNLxg"},"source":["I manuall interrupted the training because I wanted everything to have a training accuracy > 90% and I didn't code that part in yet\n","<br> <br>\n","Now I am going to test the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKD70kYxPUvl","executionInfo":{"status":"ok","timestamp":1624054785585,"user_tz":420,"elapsed":859,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"}},"outputId":"c5a38afd-98e6-4ba4-f456-eb2dfe0de780"},"source":["test(testloader, model)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Age Accuracy : 45.85530478801941%,     Gender Accuracy : 89.0107572242143,    Ethnicity Accuracy : 76.46066230753006\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WR8_D6ERNWln"},"source":["As you can see the testing accuracy is not that great. My hypothesis is that predicting age is actually a very difficult task because there is so much variation between how people age.\n","<br> <br> \n","Even between different genders and ethnicities there is so much variance. Therefore, we have both inter and intra-variance when it comes to age.\n","<br> <br>\n","Perhaps a better approach would be to feed the outputs of the gender and ethnicity classifier to the age classifier so it can use that information as well. But,that's a project for another day."]},{"cell_type":"code","metadata":{"id":"mLAdhn7wN-f-"},"source":[""],"execution_count":null,"outputs":[]}]}